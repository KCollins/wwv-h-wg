{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a696ab81-f144-40c5-b53e-f416c5c39c28",
   "metadata": {},
   "source": [
    "[Aidan's notes are in square brackets]<br> [*Cuong's notes are italicized*]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ad35d0-0c83-4b30-9f1a-0fbe97dd6c9f",
   "metadata": {},
   "source": [
    "[Very well-written with the use of functions!]<br>[*Thank you!*]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97672e1e-6877-458f-b8d8-c3bf14bc3ff3",
   "metadata": {},
   "source": [
    "[ am I correct in saying we can look for changes in the time of flight but not the time of flight itself?\n",
    "Unless someone made the recordings with a GPSDO and accurate time stamps and all. ]<br>\n",
    "[*The answer will be discussed through email*]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea0aecd",
   "metadata": {},
   "source": [
    "# Sunrise Festival Analysis Notebook\n",
    "This is the Jupyter Notebook for analyzing Sunrise Festival data (www.hamsci.org/sunrisefest). It was developed by Kristina Collins KD8OXT, based on work by Cuong Nguyen (ORCID 0000-0002-3769-7556) and other students at the University of Scranton.\n",
    "\n",
    "### Overview\n",
    "In this notebook, you'll compare your recorded signal to a template of the signal*. By finding the [cross-correlation](https://en.wikipedia.org/wiki/Cross-correlation) between parts of the template and your recording, you will identify the time at which you observed each part, and the time between parts. You will also look for evidence of multipath propagation and identify the delay between paths. After you submit your results, they will be combined with other submissions to look for the effects of sunrise on propogation around the world.\n",
    "\n",
    "_\\* The template signal is actually the same audio file used at the source transmitters WWV and WWVH! You can download and experiment with the files yourself at https://zenodo.org/record/5602094_\n",
    "\n",
    "### How to Use This Notebook\n",
    "\n",
    "*Note:* If you are running this notebook in Binder, your changes will not be saved. To make significant changes, you should download a local version.\n",
    "\n",
    "1. At the top of the screen, under \"Kernel,\" click \"Restart and Clear Output.\"\n",
    "2. Under \"Cell,\" click \"Run All.\" This may take some time to run. Verify that the notebook is able to run completely and successfully. \n",
    "3. Upload your own data file to Binder (click and drag into the folder structure at left). Change the filename and user input parameters below. Make sure you can hear the signal clearly when you submit the file.\n",
    "4. Repeat Steps 1 and 2. There are parts of the notebook where you will have to customize the code according to your data file. These spots will be indicated by text that looks like this:\n",
    "\n",
    "<div class=\"alert alert-danger\">$\\color{red}{\\text{TODO}}$ Read the directions before you begin.</div>\n",
    "\n",
    "5. Look at the results and make notes from your data.\n",
    "6. At the top of the page, select \"File > Download As > Notebook.\" \n",
    "\n",
    "\n",
    "[submit somewhere]<br>[*The answer will be discussed through email*]\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49841c69",
   "metadata": {},
   "source": [
    "## User Input Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0fb78",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">Welcome! Input your file parameters here, then run the notebook.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60217379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to the template signal\n",
    "fname = \"test.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4023c59e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">$\\color{red}{\\text{TODO}}$: Here's where you should input the filename of your audio or IQ file.</div>\n",
    "\n",
    "<!--- In this case, we're using an IQ file recorded on a KiwiSDR belonging to Phil Karn, KA9Q. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb3c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to the collected signal\n",
    "fname1 = \"N6GN_20211115T190749_iq_15.wav\"\n",
    "# fname1 = \"w2naf.com_2021-11-15T19_07_36Z_10000.00_iq.wav\"\n",
    "# fname1 = \"N6GN_20211115T190749_am_15.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44165df8-7812-40dc-bf02-b6bd97013a1a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">$\\color{red}{\\text{TODO}}$: If your signal is an IQ file, set this to True. If it is an AM file, set this to False.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d6fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the collected signal require AM modulation?\n",
    "modulation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e64ace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you want a custom sample rate as opposed to the value given by the wav files themselves?\n",
    "# Leave fs_custom = -1 if the answer is NO\n",
    "fs_custom = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb5ed39",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">$\\color{red}{\\text{TODO}}$: Let's log the date and physical location of the station where the data was collected. Note that the start time is embedded in the Kiwi filename: </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 0;\n",
    "lon = 0;\n",
    "# filestart = \"2021-11-15T19:07:36\"\n",
    "filestart = \"2022-11-15T19:07:49\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d6985",
   "metadata": {},
   "source": [
    "## Import Useful Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d408b08",
   "metadata": {},
   "source": [
    "First, we'll make sure the requisite packages are installed.\n",
    "\n",
    "If you are running this on Binder, the packages will be installed automatically.\n",
    "\n",
    "If you are not running on Binder, install the Python packages from `requirements.txt` (i.e. `pip install -r requirements.txt`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45ca34",
   "metadata": {},
   "source": [
    "Next, we'll import the packages we need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1288ca-201f-40cc-84fe-7245ce2e43d8",
   "metadata": {},
   "source": [
    "[ matplotlib has an interactive version, so we shouldn't need to import plotly in addition. However, on my computer, the matplotlib version was hanging up. ]<br>\n",
    "[*This works so I wouldn't bother changing it. Plus, there seems to be more additional steps to show matplotlib interactive plots, while plotly only requires one additional command in the command line.*]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b3891c-9028-4a54-a24d-39331466d2d8",
   "metadata": {},
   "source": [
    "[ some of these can go ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e932e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import splitext\n",
    "import gc\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import scipy.signal\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "import datetime\n",
    "\n",
    "from sunrisefest_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6157599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib settings to make the plots look a little nicer.\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['font.size']      = 18\n",
    "plt.rcParams['font.weight']    = 'bold'\n",
    "plt.rcParams['axes.grid']      = True\n",
    "plt.rcParams['axes.xmargin']   = 0\n",
    "plt.rcParams['grid.linestyle'] = ':'\n",
    "plt.rcParams['figure.figsize'] = (10,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea670f13",
   "metadata": {},
   "source": [
    "## Define Useful Functions\n",
    "Next, we'll define a few functions that will be useful later on in the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32117c6-7de9-42fd-8447-1ffc7c02991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty array to hold the results we find\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d32c0-edbd-4df2-bffa-2f9750b3787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record(name: str, description: str, value, unit: str):\n",
    "    '''Record a result of our analysis'''\n",
    "    \n",
    "    print(description.format(value))\n",
    "    \n",
    "    results.append({\n",
    "        \"name\": name,\n",
    "        \"description\": description,\n",
    "        \"value\": value,\n",
    "        \"unit\": unit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f07cc2-969d-442f-ad86-9d0bb66dbea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results():\n",
    "    '''Save the results to a file'''\n",
    "    \n",
    "    output_file = splitext(fname1)[0] + \"-results.json\"\n",
    "    print(f\"writing to file {output_file}\")\n",
    "    \n",
    "    with open(output_file, 'w') as file:\n",
    "        json.dump({\n",
    "            \"fname1\": fname1,\n",
    "            \"fs_custom\": fs_custom,\n",
    "            \"modulation\": modulation,\n",
    "            \"original sample rate\": fs_wav1,\n",
    "            \"upsampled sample rate\": fs_upsampled_wav1,\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"results\": results\n",
    "        }, file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6299bd0d",
   "metadata": {},
   "source": [
    "## Load manufactured signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc6a668-634e-4bf2-b4b6-cc607e8f0be5",
   "metadata": {},
   "source": [
    "Before we load your recording, we'll load the template signal and extract a few key parts of the template. We'll save each of these parts into variables so that we can compare them to your recording later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a0aa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the file and detect the sampling frequency\n",
    "fs_wav0, wav0 = wavfile.read(fname)\n",
    "\n",
    "# Create a time vector\n",
    "t_wav0 = np.arange(len(wav0)) * (1./fs_wav0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae165e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the sounddevice library, we can hear what the template sounds like if played as\n",
    "play(wav0, fs_wav0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613023a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "wav0_n = norm(wav0)\n",
    "wav0_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f1416-721c-4203-a2e8-7fdb8c4a4ec4",
   "metadata": {},
   "source": [
    "[ fix divide by zero errors ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb6110",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signal(t_wav0, wav0_n, title=\"Manufactured Signal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d8fb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extract white noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b841c8b-a942-4465-9d3b-dd3912804220",
   "metadata": {},
   "source": [
    "The first part of the signal we are interested in is the burst of white noise. If second 0 is the start of the signal, the same 2 second burst is sent at seconds 10 - 12 and at seconds 37 - 39. Here, we'll grab the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e00158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the white noise\n",
    "white_noise, t_white_noise = extract(wav0_n, 10, 12, fs_wav0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39428a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the white noise\n",
    "# plot_signal(t_white_noise, white_noise, title=\"Extracted White Noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1926bf45-62ae-4983-a0e2-4a119dea0c15",
   "metadata": {},
   "source": [
    "In this experiment, we are interested in the time between the first and second burst of noise. We can find the time of each burst in the recording by finding the maximum cross-correlation between the ideal burst and the recording. We would then take the difference of these times to find the time between bursts.\n",
    "\n",
    "To illustrate how this will work, let's cross-correlate the noise we extracted with the entire template signal. This simulates an ideal case where we could record the signal without propagation delay, interference, ambient noise, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f632a9-85fb-44aa-8cf2-6696d55413e1",
   "metadata": {},
   "source": [
    "[ Is it more helpful to have this written out each time, or to make it a function ? ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_test_white, t_test_white = crosscorrelate(wav0_n, white_noise, fs_wav0)\n",
    "\n",
    "plot_correlation(t_test_white, R_test_white, title='Full Manufactured Signal vs. Manufactured White Noise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600cbeec-eea5-4591-b787-961ff988400c",
   "metadata": {},
   "source": [
    "The cross-correlation has two large peaks corresponding to the beginnings of each burst of white noise. Since this is an ideal case, the peaks occur at 10 and 37 seconds exactly, and we can subtract the two times to get a time of 27 seconds between bursts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b306618a",
   "metadata": {},
   "source": [
    "### Extract Chirps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd77625-e450-498f-b6ee-8b94de859484",
   "metadata": {},
   "source": [
    "The next part of the signal we'll look at is the chirp sounds. These occur in the template signal between 24 and 32 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b8a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chirps, t_chirps = extract(wav0_n, 24, 32, fs_wav0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2568da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signal(t_chirps, chirps, title=\"Extracted Chirps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd43893-b782-4821-8395-d16a90436079",
   "metadata": {},
   "source": [
    "If we repeat the same cross-correlation procedure, we can find the start time of the chirps in the template signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fac0573-b5cd-4fdc-967a-203e4d6f99f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_test_chirps, t_test_chirps = crosscorrelate(wav0_n, chirps, fs_wav0)\n",
    "\n",
    "plot_correlation(t_test_chirps, R_test_chirps, title='Cross-Correlation between the Full Manufactured Signal and Manufactured Chirps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab233c7-2119-4942-b4e7-d4ee3e89da84",
   "metadata": {},
   "source": [
    "Here, there are multiple peaks because the chirps repeat themselves. We are interested in the largest peak, which corresponds to the best match between the template and the signal.\n",
    "\n",
    "The largest peak occurs at 24 seconds, which is the start time of the chirps as we expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef8bc90",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load the Recorded Data and Perform AM Demodulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce91bf4f-c2a0-41f9-83e2-828f1a8135a4",
   "metadata": {},
   "source": [
    "Now that we have our templates, we will load your recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4a108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that IQ WAV files look like regular stereo WAV files, but instead of \n",
    "# the channels representing the left and right speakers, they represent the\n",
    "# I and Q signals.\n",
    "\n",
    "fs_wav1, iq = wavfile.read(fname1)\n",
    "t_wav1      = np.arange(len(iq))*(1./fs_wav1)\n",
    "\n",
    "print('Sample Rate: {!s} samples/sec'.format(fs_wav1))\n",
    "if modulation:\n",
    "    print('Number of Channels: {!s}'.format(iq.shape[1]))\n",
    "print('Data Type: {!s}'.format(iq.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c380ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_float = iq / (np.max(np.abs(iq))+1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c7a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this signal requires AM demodulation, do that:\n",
    "if modulation:\n",
    "    wav1 = np.sqrt(iq_float[:,0]**2 + iq_float[:,1]**2)\n",
    "else:\n",
    "    wav1 = iq_float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99ad202",
   "metadata": {},
   "source": [
    "Let's listen to the file we've imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e9e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "play(wav1, fs_wav1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e49f65e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">$\\color{red}{\\text{TODO}}$: Manually clip the signal to just the part we're interested in - starting a second or so before the test signal starts, ending about a minute later.</div>\n",
    "\n",
    "[Explain what the user is supposed to do here.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9df6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav1 = extract(wav1, 50, 110, fs_wav1) # Extract at 50 and 110 seconds\n",
    "# t_wav1      = np.arange(len(iq))*(1./fs_wav1) # Make sure time variable is consistent\n",
    "play(wav1, fs_wav1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df03e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "wav1_n = norm(wav1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7a2372",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signal(t_wav1, wav1_n, title=fname1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267a58ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Remove the DC Offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3170d30-13f2-4dd7-84f2-507b401474be",
   "metadata": {},
   "source": [
    "[ explain ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b802b3-37de-4aea-91a0-a0424aa94b0f",
   "metadata": {},
   "source": [
    "[ maybe a less confusing variable name? ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524390f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav1_offset = dco(wav1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d023a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signal(t_wav1, wav1_offset, title='DC-Removed '+fname1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00168d46-e44d-4176-83cd-cabfd5c118c3",
   "metadata": {},
   "source": [
    "## Resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f73ab3c-25fa-432f-b340-07e8cca3209c",
   "metadata": {},
   "source": [
    "[ explain ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a9cd26-090f-44d2-a7af-acdf09a06e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_number_of_samples = int(len(wav1_offset)/fs_wav1*fs_wav0)\n",
    "print(\"Total number of samples in the collected signal: \",new_number_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c4384-eb6d-46ba-be45-28e156f73597",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_upsampled_wav1 = fs_wav0\n",
    "print(\"New sampling rate of collected signal: {:f} samples per second\".format(fs_upsampled_wav1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb89118b-c7a3-4c2e-8672-abf7c9a0396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_wav1, t_upsampled_wav1 = signal.resample(wav1_offset, new_number_of_samples, t=t_wav1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19bd11c-b97d-4716-a548-734925755107",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_signal(t_upsampled_wav1, upsampled_wav1, title='Resampled Received Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f398ed4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Timing of the Collected Chirps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a02e0d-d320-4b52-b282-acb58a228642",
   "metadata": {},
   "source": [
    "Now we will implement the procedure we described earlier: cross-correlate the template with your recording and identify the time of best correlation. This procedure is implemented in the `find_timing_of` method.<br>\n",
    "\n",
    "First, we can cross-correlate the template chirps with our entire recording:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca06987-f6c3-4c7d-a700-f1e9d7ada582",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_upsampled_chirps = find_timing_of(chirps, upsampled_wav1, fs_upsampled_wav1)\n",
    "print(\"Start Time of the Chirps relative to the beginning of the recording: {:f} seconds\".format(t_upsampled_chirps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0b562",
   "metadata": {},
   "source": [
    "## Timing of the First White Gaussian Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc2ac9f-6b30-4a87-a2b0-45ad331e47a7",
   "metadata": {},
   "source": [
    "We know that the first white noise burst happens before the chirps. So, we will restrict our search for the first white Gaussian noise from the beginning of the recording up to the timing of the chirps which was found in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff3991a-f423-4fee-8ea0-630fdf3ac445",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav1_extract_for_t1, t_wav1_extract_for_t1 = extract(upsampled_wav1, 'start', t_upsampled_chirps, fs_upsampled_wav1)\n",
    "wav1_extract_for_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235273da",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = find_timing_of(white_noise, wav1_extract_for_t1, fs_upsampled_wav1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18d984c-5048-4708-98bb-0bb9b859385b",
   "metadata": {},
   "source": [
    "This variable, `t1`, is our first finding. We'll save it for later using the `record` helper function. (At the end of this notebook, we'll write everything saved with `record` to a file that you can submit along with your raw recording.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62db1a7-11d8-4816-b056-2d245dc50f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "record('t1', 'Start time of the first white Gaussian noise with respect to the beginning of the recording: {:f} seconds', t1, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4ca1e-4627-41f9-a31b-96bae6cb1a92",
   "metadata": {},
   "source": [
    "It is useful to find the timing of the chirps with respect to the timing of the first white noise burst, so we will save it for later as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef43e2-27fa-4123-a976-d3cd51858919",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_chirps_wrt_t1 = t_upsampled_chirps - t1\n",
    "record(\n",
    "    't_chirps_wrt_t1',\n",
    "    \"Start Time of the Chirps with respect to Start Time of the First Noise: {:f} seconds\",\n",
    "    t_chirps_wrt_t1,\n",
    "    'seconds')\n",
    "print(\"Start Time of the Chirps with respect to Start Time of the First Noise: {:f} seconds\".format(t_upsampled_chirps + t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e102b",
   "metadata": {},
   "source": [
    "## Timing of the Second White Gaussian Noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465a4a0-d700-4c17-9c79-e131f0786271",
   "metadata": {},
   "source": [
    "Now we'll find how long after the first white noise the second noise starts.<br>\n",
    "\n",
    "Once again, we can restrict our search to after the timing of the chirps found in the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca2b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collected signal extracted without the portion before the end of the chirps (approximately\n",
    "wav1_extract_for_t2, t_wav1_extract_for_t2  = extract(upsampled_wav1, t_upsampled_chirps, 'end', fs_upsampled_wav1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d4279-ec02-4621-99d1-7eeaafa60c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = find_timing_of(white_noise, wav1_extract_for_t2, fs_upsampled_wav1) + t_chirps_wrt_t1\n",
    "\n",
    "record(\n",
    "    't2',\n",
    "    \"Start time of the second white Gaussian noise with respect to the first white Gaussian noise: {:f} seconds.\",\n",
    "    t2,\n",
    "    \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57225f92-27c1-4029-8ed9-23fa7ba6259b",
   "metadata": {},
   "source": [
    "We can also find the time of second burst relative to the beginning of the recording by adding the times `t1` and `t2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc5ed30-1b0d-4438-8fae-7819e228c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start time of the second white Gaussian noise with respect to the beginning of the recording: {:f} seconds.\".format(t2 + t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b03710f-57a2-4e71-9251-ac2e17f310bd",
   "metadata": {},
   "source": [
    "## Look for multipath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c6828-8436-4efc-abcd-a81196d88da6",
   "metadata": {},
   "source": [
    "Let's investigate the correlation plot between the collected signal and the template chirps, and save the plot to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f8caf4-3671-4859-9c36-6a876c693d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_chirps, tau_chirps = crosscorrelate(upsampled_wav1, chirps, fs_upsampled_wav1)\n",
    "\n",
    "fig = plot_correlation(tau_chirps, R_chirps, title='Cross-Correlation between Template Chirps and Signal between Noises\\nsignal: {}'.format(fname1), return_figure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77567d99-fbaa-4abe-b335-23f64fc8f8fa",
   "metadata": {},
   "source": [
    "[ could we make a clearer illustration for the correlations ? ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b923d77-d69a-4ec8-99be-3656802a7477",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(splitext(fname1)[0] + \"-results.png\", dpi=300, facecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8966dd20-0c03-454d-b8f4-5c7e3bc49898",
   "metadata": {},
   "source": [
    "In addition to the five large peaks, you might (or might not) see smaller peaks that are delayed slightly. If you can see them, they are likely evidence that you received the signal along more than one propagation path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f1868c-c0e1-48ff-ae00-1a1479183c78",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">Do you see multipath? (Set the variable to True if you do, False if you don't.)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebdf812-4813-4657-b219-863d3241fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "multipath = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b055cf-4280-4af0-bcc0-4d5eb6bc38e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "record('multipath', 'user saw multipath? {}', multipath, 'yes/no')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c38e89c-96b4-4d3a-84b2-bdb05d91284e",
   "metadata": {},
   "source": [
    "Let's make an interactive version of this plot so we can zoom in and identify the location of the peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb2b01c-801a-4b8c-a6de-8fcda7de0ce2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><p>Uncomment the following line of code to generate an interactive plot.</p>\n",
    "    <p><i>Uncomment Python code by removing the '#' before a line.</i></p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdc858e-89dc-4583-bed1-71ef072c656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_peaks, t_peaks = plot_correlation_interactive(tau_chirps, R_chirps, title='Cross-correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ff6a86-e31a-47a5-a53a-2e76e35d0485",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><p>Zoom in to the area with the five peaks. How many different propagation paths can you see?</p>\n",
    "<p>Set the variable to the number of paths you see. Remember, a group of five large peaks by themselves means you heard only one path. If the large peaks are each followed by one smaller 'echo', you heard a second path. If there were two 'echos', you heard 3 paths, etc.</p></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d3987-7770-4296-bbdb-e695cbd087c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_paths = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f518b-23e2-4e09-a54b-5346b2f1c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "record('number_of_paths', 'The user was able to identify {} paths', number_of_paths, 'count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f671a457-3f60-4c81-96a0-185ed2a9354b",
   "metadata": {},
   "source": [
    "We'll next save the peaks that were found in the cross-correlation (the red plus marks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5df02-1a6a-4a68-a90a-78f7467d88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "record('R_peaks', 'Array of amplitudes of peaks: {}', R_peaks, 'unitless (cross-correlation)')\n",
    "record('t_peaks', 'Array of times of peaks: {}', t_peaks, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613e11cc-f841-4371-83c2-bcf1929ea36f",
   "metadata": {},
   "source": [
    "[ the peak finding method needs tuning. ]<br>\n",
    "[*Work in progress*]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49fcbe4-63c7-40ee-b4f0-5c90a75c922f",
   "metadata": {},
   "source": [
    "## Output results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7cea5a-6a8a-4cd1-ad66-66213c03a8fd",
   "metadata": {},
   "source": [
    "Finally, write the results we've been saving with the `record` function to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d42ee2-f3bf-423c-97ab-e84ff479384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d8875-35d8-419f-ad7f-8738557e032f",
   "metadata": {},
   "source": [
    "## The End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff401f-8735-40d9-ab9f-bcaea1adabbe",
   "metadata": {},
   "source": [
    "That's it! Along with your recording, submit both the `.json` file with your numerical results and the `.png` file with your plot of the chirp correlations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
